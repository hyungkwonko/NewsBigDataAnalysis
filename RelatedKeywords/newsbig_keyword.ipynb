{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "komoran = Komoran()\n",
    "kkma = Kkma()\n",
    "okt = Okt()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-     For Korean words\n",
    "\n",
    "\n",
    "path_dir = '/home/minkh/Downloads/twitter/'\n",
    "file_list = os.listdir(path_dir)\n",
    "file_list.sort()\n",
    "\n",
    "filenames =[]\n",
    "for i in range(len(file_list)):\n",
    "    filenames.append(file_list[i])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_20180701.json',\n",
       " 'twitter_20180702.json',\n",
       " 'twitter_20180703.json',\n",
       " 'twitter_20180704.json',\n",
       " 'twitter_20180705.json',\n",
       " 'twitter_20180706.json',\n",
       " 'twitter_20180707.json',\n",
       " 'twitter_20180708.json',\n",
       " 'twitter_20180709.json',\n",
       " 'twitter_20180710.json',\n",
       " 'twitter_20180711.json',\n",
       " 'twitter_20180712.json',\n",
       " 'twitter_20180713.json',\n",
       " 'twitter_20180714.json',\n",
       " 'twitter_20180715.json',\n",
       " 'twitter_20180716.json',\n",
       " 'twitter_20180717.json',\n",
       " 'twitter_20180718.json',\n",
       " 'twitter_20180719.json',\n",
       " 'twitter_20180720.json',\n",
       " 'twitter_20180721.json',\n",
       " 'twitter_20180722.json',\n",
       " 'twitter_20180723.json',\n",
       " 'twitter_20180724.json',\n",
       " 'twitter_20180725.json',\n",
       " 'twitter_20180726.json',\n",
       " 'twitter_20180727.json',\n",
       " 'twitter_20180728.json',\n",
       " 'twitter_20180729.json',\n",
       " 'twitter_20180730.json',\n",
       " 'twitter_20180731.json',\n",
       " 'twitter_20180801.json',\n",
       " 'twitter_20180802.json',\n",
       " 'twitter_20180803.json',\n",
       " 'twitter_20180804.json',\n",
       " 'twitter_20180805.json',\n",
       " 'twitter_20180806.json',\n",
       " 'twitter_20180807.json',\n",
       " 'twitter_20180808.json',\n",
       " 'twitter_20180809.json',\n",
       " 'twitter_20180810.json',\n",
       " 'twitter_20180811.json',\n",
       " 'twitter_20180812.json',\n",
       " 'twitter_20180813.json',\n",
       " 'twitter_20180814.json',\n",
       " 'twitter_20180815.json',\n",
       " 'twitter_20180816.json',\n",
       " 'twitter_20180817.json',\n",
       " 'twitter_20180818.json',\n",
       " 'twitter_20180819.json',\n",
       " 'twitter_20180820.json',\n",
       " 'twitter_20180821.json',\n",
       " 'twitter_20180822.json',\n",
       " 'twitter_20180823.json',\n",
       " 'twitter_20180824.json',\n",
       " 'twitter_20180825.json',\n",
       " 'twitter_20180826.json',\n",
       " 'twitter_20180827.json',\n",
       " 'twitter_20180828.json',\n",
       " 'twitter_20180829.json',\n",
       " 'twitter_20180830.json',\n",
       " 'twitter_20180831.json',\n",
       " 'twitter_20180901.json',\n",
       " 'twitter_20180902.json',\n",
       " 'twitter_20180903.json',\n",
       " 'twitter_20180904.json',\n",
       " 'twitter_20180905.json',\n",
       " 'twitter_20180906.json',\n",
       " 'twitter_20180907.json',\n",
       " 'twitter_20180908.json',\n",
       " 'twitter_20180909.json',\n",
       " 'twitter_20180910.json',\n",
       " 'twitter_20180911.json',\n",
       " 'twitter_20180912.json',\n",
       " 'twitter_20180913.json',\n",
       " 'twitter_20180914.json',\n",
       " 'twitter_20180915.json',\n",
       " 'twitter_20180916.json',\n",
       " 'twitter_20180917.json',\n",
       " 'twitter_20180918.json',\n",
       " 'twitter_20180919.json',\n",
       " 'twitter_20180920.json',\n",
       " 'twitter_20180921.json',\n",
       " 'twitter_20180922.json',\n",
       " 'twitter_20180923.json',\n",
       " 'twitter_20180924.json',\n",
       " 'twitter_20180925.json',\n",
       " 'twitter_20180926.json',\n",
       " 'twitter_20180927.json',\n",
       " 'twitter_20180928.json',\n",
       " 'twitter_20180929.json',\n",
       " 'twitter_20180930.json',\n",
       " 'twitter_20181001.json',\n",
       " 'twitter_20181002.json',\n",
       " 'twitter_20181003.json',\n",
       " 'twitter_20181004.json',\n",
       " 'twitter_20181005.json',\n",
       " 'twitter_20181006.json',\n",
       " 'twitter_20181007.json',\n",
       " 'twitter_20181008.json',\n",
       " 'twitter_20181009.json',\n",
       " 'twitter_20181010.json',\n",
       " 'twitter_20181011.json',\n",
       " 'twitter_20181012.json',\n",
       " 'twitter_20181013.json',\n",
       " 'twitter_20181014.json',\n",
       " 'twitter_20181015.json',\n",
       " 'twitter_20181016.json',\n",
       " 'twitter_20181017.json',\n",
       " 'twitter_20181018.json',\n",
       " 'twitter_20181019.json',\n",
       " 'twitter_20181020.json',\n",
       " 'twitter_20181021.json',\n",
       " 'twitter_20181022.json',\n",
       " 'twitter_20181023.json',\n",
       " 'twitter_20181024.json',\n",
       " 'twitter_20181025.json',\n",
       " 'twitter_20181026.json',\n",
       " 'twitter_20181027.json',\n",
       " 'twitter_20181028.json',\n",
       " 'twitter_20181029.json',\n",
       " 'twitter_20181030.json',\n",
       " 'twitter_20181031.json',\n",
       " 'twitter_20181101.json',\n",
       " 'twitter_20181102.json',\n",
       " 'twitter_20181103.json',\n",
       " 'twitter_20181104.json',\n",
       " 'twitter_20181105.json',\n",
       " 'twitter_20181106.json',\n",
       " 'twitter_20181107.json',\n",
       " 'twitter_20181108.json',\n",
       " 'twitter_20181109.json',\n",
       " 'twitter_20181110.json',\n",
       " 'twitter_20181111.json',\n",
       " 'twitter_20181112.json',\n",
       " 'twitter_20181113.json',\n",
       " 'twitter_20181114.json',\n",
       " 'twitter_20181115.json',\n",
       " 'twitter_20181116.json',\n",
       " 'twitter_20181117.json',\n",
       " 'twitter_20181118.json',\n",
       " 'twitter_20181119.json',\n",
       " 'twitter_20181120.json',\n",
       " 'twitter_20181121.json',\n",
       " 'twitter_20181122.json',\n",
       " 'twitter_20181123.json',\n",
       " 'twitter_20181124.json',\n",
       " 'twitter_20181125.json',\n",
       " 'twitter_20181126.json',\n",
       " 'twitter_20181127.json',\n",
       " 'twitter_20181128.json',\n",
       " 'twitter_20181129.json',\n",
       " 'twitter_20181130.json',\n",
       " 'twitter_20181201.json',\n",
       " 'twitter_20181202.json',\n",
       " 'twitter_20181203.json',\n",
       " 'twitter_20181204.json',\n",
       " 'twitter_20181205.json',\n",
       " 'twitter_20181206.json',\n",
       " 'twitter_20181207.json',\n",
       " 'twitter_20181208.json',\n",
       " 'twitter_20181209.json',\n",
       " 'twitter_20181210.json',\n",
       " 'twitter_20181211.json',\n",
       " 'twitter_20181212.json',\n",
       " 'twitter_20181213.json',\n",
       " 'twitter_20181214.json',\n",
       " 'twitter_20181215.json',\n",
       " 'twitter_20181216.json',\n",
       " 'twitter_20181217.json',\n",
       " 'twitter_20181218.json',\n",
       " 'twitter_20181219.json',\n",
       " 'twitter_20181220.json',\n",
       " 'twitter_20181221.json',\n",
       " 'twitter_20181222.json',\n",
       " 'twitter_20181223.json',\n",
       " 'twitter_20181224.json',\n",
       " 'twitter_20181225.json',\n",
       " 'twitter_20181226.json',\n",
       " 'twitter_20181227.json',\n",
       " 'twitter_20181228.json',\n",
       " 'twitter_20181229.json',\n",
       " 'twitter_20181230.json',\n",
       " 'twitter_20181231.json',\n",
       " 'twitter_20190101.json',\n",
       " 'twitter_20190102.json',\n",
       " 'twitter_20190103.json',\n",
       " 'twitter_20190104.json',\n",
       " 'twitter_20190105.json',\n",
       " 'twitter_20190106.json',\n",
       " 'twitter_20190107.json',\n",
       " 'twitter_20190108.json',\n",
       " 'twitter_20190109.json',\n",
       " 'twitter_20190110.json',\n",
       " 'twitter_20190111.json',\n",
       " 'twitter_20190112.json',\n",
       " 'twitter_20190113.json',\n",
       " 'twitter_20190114.json',\n",
       " 'twitter_20190115.json',\n",
       " 'twitter_20190116.json',\n",
       " 'twitter_20190117.json',\n",
       " 'twitter_20190118.json',\n",
       " 'twitter_20190119.json',\n",
       " 'twitter_20190120.json',\n",
       " 'twitter_20190121.json',\n",
       " 'twitter_20190122.json',\n",
       " 'twitter_20190123.json',\n",
       " 'twitter_20190124.json',\n",
       " 'twitter_20190125.json',\n",
       " 'twitter_20190126.json',\n",
       " 'twitter_20190127.json',\n",
       " 'twitter_20190128.json',\n",
       " 'twitter_20190129.json',\n",
       " 'twitter_20190130.json',\n",
       " 'twitter_20190131.json',\n",
       " 'twitter_20190201.json',\n",
       " 'twitter_20190202.json',\n",
       " 'twitter_20190203.json',\n",
       " 'twitter_20190204.json',\n",
       " 'twitter_20190205.json',\n",
       " 'twitter_20190206.json',\n",
       " 'twitter_20190207.json',\n",
       " 'twitter_20190208.json',\n",
       " 'twitter_20190209.json',\n",
       " 'twitter_20190210.json',\n",
       " 'twitter_20190211.json',\n",
       " 'twitter_20190212.json',\n",
       " 'twitter_20190213.json',\n",
       " 'twitter_20190214.json',\n",
       " 'twitter_20190215.json',\n",
       " 'twitter_20190216.json',\n",
       " 'twitter_20190217.json',\n",
       " 'twitter_20190218.json',\n",
       " 'twitter_20190219.json',\n",
       " 'twitter_20190220.json',\n",
       " 'twitter_20190221.json',\n",
       " 'twitter_20190222.json',\n",
       " 'twitter_20190223.json',\n",
       " 'twitter_20190224.json',\n",
       " 'twitter_20190225.json',\n",
       " 'twitter_20190226.json',\n",
       " 'twitter_20190227.json',\n",
       " 'twitter_20190228.json',\n",
       " 'twitter_20190301.json',\n",
       " 'twitter_20190302.json',\n",
       " 'twitter_20190303.json',\n",
       " 'twitter_20190304.json',\n",
       " 'twitter_20190305.json',\n",
       " 'twitter_20190306.json',\n",
       " 'twitter_20190307.json',\n",
       " 'twitter_20190308.json',\n",
       " 'twitter_20190309.json',\n",
       " 'twitter_20190310.json',\n",
       " 'twitter_20190311.json',\n",
       " 'twitter_20190312.json',\n",
       " 'twitter_20190313.json',\n",
       " 'twitter_20190314.json',\n",
       " 'twitter_20190315.json',\n",
       " 'twitter_20190316.json',\n",
       " 'twitter_20190317.json',\n",
       " 'twitter_20190318.json',\n",
       " 'twitter_20190319.json',\n",
       " 'twitter_20190320.json',\n",
       " 'twitter_20190321.json',\n",
       " 'twitter_20190322.json',\n",
       " 'twitter_20190323.json',\n",
       " 'twitter_20190324.json',\n",
       " 'twitter_20190325.json',\n",
       " 'twitter_20190326.json',\n",
       " 'twitter_20190327.json',\n",
       " 'twitter_20190328.json',\n",
       " 'twitter_20190329.json',\n",
       " 'twitter_20190330.json',\n",
       " 'twitter_20190331.json',\n",
       " 'twitter_20190401.json',\n",
       " 'twitter_20190402.json',\n",
       " 'twitter_20190403.json',\n",
       " 'twitter_20190404.json',\n",
       " 'twitter_20190405.json',\n",
       " 'twitter_20190406.json',\n",
       " 'twitter_20190407.json',\n",
       " 'twitter_20190408.json',\n",
       " 'twitter_20190409.json',\n",
       " 'twitter_20190410.json',\n",
       " 'twitter_20190411.json',\n",
       " 'twitter_20190412.json',\n",
       " 'twitter_20190413.json',\n",
       " 'twitter_20190414.json',\n",
       " 'twitter_20190415.json',\n",
       " 'twitter_20190416.json',\n",
       " 'twitter_20190417.json',\n",
       " 'twitter_20190418.json',\n",
       " 'twitter_20190419.json',\n",
       " 'twitter_20190420.json',\n",
       " 'twitter_20190421.json',\n",
       " 'twitter_20190422.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.index('twitter_20180706.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type clicked time  ex.2019031220190410\n"
     ]
    }
   ],
   "source": [
    "given_time = input('type clicked time  ex.20190312')\n",
    "\n",
    "\n",
    "search_range = []\n",
    "\n",
    "for i in range(7):\n",
    "    pointed = 'twitter_{0}.json'.format(given_time)\n",
    "    search_range.append(filenames[filenames.index(pointed)-i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitter_20190410.json',\n",
       " 'twitter_20190409.json',\n",
       " 'twitter_20190408.json',\n",
       " 'twitter_20190407.json',\n",
       " 'twitter_20190406.json',\n",
       " 'twitter_20190405.json',\n",
       " 'twitter_20190404.json']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:43<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "merged =[]\n",
    "\n",
    "for k in tqdm(search_range):\n",
    "    with open('/home/minkh/Downloads/twitter/{0}'.format(k), encoding='utf-8-sig') as data_file:\n",
    "        for line in data_file:\n",
    "            try:\n",
    "                j = line.split('|')[-1]\n",
    "                merged.append(json.loads(j))\n",
    "            except ValueError:\n",
    "                # You probably have bad JSON\n",
    "                continue\n",
    "\n",
    "# list to dataframe\n",
    "df = pd.DataFrame(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [{'indices': [35, 39]...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/mq...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121208771604486</td>\n",
       "      <td>1105121208771604486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2123</td>\n",
       "      <td>False</td>\n",
       "      <td>{'extended_entities': {'media': [{'display_url...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @mayrabbitprince: 190311 마시타 퇴근 #박지훈 #지훈\\n\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 56, 'pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [{'indices': [44, 48]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207752511488</td>\n",
       "      <td>1105121207752511488</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7500</td>\n",
       "      <td>False</td>\n",
       "      <td>{'metadata': {'result_type': 'recent', 'iso_la...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @M2MPD: &amp;lt;찾았다 스트레이 키즈&amp;gt; PHOTO TEASER #아...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 198, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207735660545</td>\n",
       "      <td>1105121207735660545</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>403</td>\n",
       "      <td>False</td>\n",
       "      <td>{'metadata': {'result_type': 'recent', 'iso_la...</td>\n",
       "      <td>&lt;a href=\"https://about.twitter.com/products/tw...</td>\n",
       "      <td>RT @hanna_3542: 로맨스는 별책부록 1화에서 이나영이 여기저기 면접 보고...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 133, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [{'display_url': 'mediatoday.co.kr/?m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121207366512641</td>\n",
       "      <td>1105121207366512641</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>저널리즘토크쇼J가 저격한 조선.동아일보의 친일 행적 https://t.co/0A9x...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 154, 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mon Mar 11 15:00:02 +0000 2019</td>\n",
       "      <td>{'urls': [], 'hashtags': [], 'user_mentions': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1105121206871646208</td>\n",
       "      <td>1105121206871646208</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>@vmstck 저어는 계속 ios를 썼어서...</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'friends_count': 85, 'pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  contributors coordinates                      created_at  \\\n",
       "0         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "1         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "2         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "3         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "4         None        None  Mon Mar 11 15:00:02 +0000 2019   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'urls': [], 'hashtags': [{'indices': [35, 39]...   \n",
       "1  {'urls': [], 'hashtags': [{'indices': [44, 48]...   \n",
       "2  {'urls': [], 'hashtags': [], 'user_mentions': ...   \n",
       "3  {'urls': [{'display_url': 'mediatoday.co.kr/?m...   \n",
       "4  {'urls': [], 'hashtags': [], 'user_mentions': ...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'display_url': 'pic.twitter.com/mq...               0   \n",
       "1                                                NaN               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited   geo                   id               id_str  ...  \\\n",
       "0      False  None  1105121208771604486  1105121208771604486  ...   \n",
       "1      False  None  1105121207752511488  1105121207752511488  ...   \n",
       "2      False  None  1105121207735660545  1105121207735660545  ...   \n",
       "3      False  None  1105121207366512641  1105121207366512641  ...   \n",
       "4      False  None  1105121206871646208  1105121206871646208  ...   \n",
       "\n",
       "  quoted_status  quoted_status_id quoted_status_id_str  retweet_count  \\\n",
       "0           NaN               NaN                  NaN           2123   \n",
       "1           NaN               NaN                  NaN           7500   \n",
       "2           NaN               NaN                  NaN            403   \n",
       "3           NaN               NaN                  NaN              0   \n",
       "4           NaN               NaN                  NaN              0   \n",
       "\n",
       "  retweeted                                   retweeted_status  \\\n",
       "0     False  {'extended_entities': {'media': [{'display_url...   \n",
       "1     False  {'metadata': {'result_type': 'recent', 'iso_la...   \n",
       "2     False  {'metadata': {'result_type': 'recent', 'iso_la...   \n",
       "3     False                                                NaN   \n",
       "4     False                                                NaN   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"https://about.twitter.com/products/tw...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text truncated  \\\n",
       "0  RT @mayrabbitprince: 190311 마시타 퇴근 #박지훈 #지훈\\n\\...     False   \n",
       "1  RT @M2MPD: &lt;찾았다 스트레이 키즈&gt; PHOTO TEASER #아...     False   \n",
       "2  RT @hanna_3542: 로맨스는 별책부록 1화에서 이나영이 여기저기 면접 보고...     False   \n",
       "3  저널리즘토크쇼J가 저격한 조선.동아일보의 친일 행적 https://t.co/0A9x...     False   \n",
       "4                         @vmstck 저어는 계속 ios를 썼어서...     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': None, 'friends_count': 56, 'pro...  \n",
       "1  {'utc_offset': None, 'friends_count': 198, 'pr...  \n",
       "2  {'utc_offset': None, 'friends_count': 133, 'pr...  \n",
       "3  {'utc_offset': None, 'friends_count': 154, 'pr...  \n",
       "4  {'utc_offset': None, 'friends_count': 85, 'pro...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480377"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['created_at','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date reformatting\n",
    "month = {'Jan': '01', 'Feb': '02', 'Mar': '03','Apr': '04','May': '05','Jun': '06','Jul': '07','Aug': '08', 'Sep': '09','Oct': '10','Nov': '11','Dec': '12'}\n",
    "time_format = [5,1,2,3,4,0]\n",
    "\n",
    "\n",
    "timelist = []\n",
    "for i in range(len(data)):\n",
    "    timelist.append(data['created_at'][i])\n",
    "    \n",
    "def time_reformulate(ori_list, order):\n",
    "    temp = [0]*len(ori_list)\n",
    "    temp = [ori_list[x] for x in order]\n",
    "    temp[1] = month[temp[1]]\n",
    "    time = '. '.join(temp[:4])\n",
    "    return time\n",
    "\n",
    "for i in range(len(timelist)):\n",
    "    timelist[i] = time_reformulate(timelist[i].split(),time_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to list\n",
    "text = []\n",
    "for i in range(len(data)):\n",
    "    text.append(data['text'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  list --> [time, text]\n",
    "\n",
    "data = []\n",
    "for i in range(len(timelist)):\n",
    "    data.append([timelist[i], text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaner\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]', '', cleaned_text)\n",
    "    cleaned_text = re.sub('\\n', '', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i][1] = clean_text(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i in range(len(data)):\n",
    "    tweets.append(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480377/480377 [1:05:12<00:00, 122.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweets):\n",
    "    tweets[tweets.index(tweet)] = okt.nouns(tweet)\n",
    "    #sents[sents.index(i)] = komoran.nouns(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 318674/318674 [20:42<00:00, 256.38it/s]\n"
     ]
    }
   ],
   "source": [
    "tweets_kmr = []\n",
    "for i in range(len(data)):\n",
    "    tweets_kmr.append(data[i][1])\n",
    "\n",
    "for tweet in tqdm(tweets_kmr):\n",
    "    #tweets[tweets.index(tweet)] = okt.nouns(tweet)\n",
    "    tweets_kmr[tweets_kmr.index(tweet)] = komoran.nouns(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(timelist)):\n",
    "    data.append([timelist[i], text[i], tweets_kmr[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드를 입력하세요: 정준영\n"
     ]
    }
   ],
   "source": [
    "# keyword 입력받고\n",
    "# tweet 들 중에 해당 키워드가 있으면\n",
    "# 어떤 키워드들이 많이 나오는지~\n",
    "\n",
    "keyword = input(\"키워드를 입력하세요: \") # 첫페이지에서 사용자가 입력한 것\n",
    "#timestamp = '사용자가 클릭한 시점' # 넘겨받아와서~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nouns = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i][2])):\n",
    "        bag_nouns.append(data[i][2][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3357229"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nouns = list(set(bag_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36893"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_cnt = dict.fromkeys(bag_nouns,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(data)):\n",
    "    if keyword in data[i][2]:\n",
    "        for noun in data[i][2]:\n",
    "            noun_cnt[noun] = noun_cnt[noun] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    " \n",
    "related_keywords = sorted(noun_cnt.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('정준영', 182),\n",
       " ('킴', 117),\n",
       " ('방', 97),\n",
       " ('단', 93),\n",
       " ('음란물', 93),\n",
       " ('신규', 90),\n",
       " ('에디', 77),\n",
       " ('가수', 74),\n",
       " ('것', 62),\n",
       " ('등', 52),\n",
       " ('카', 47),\n",
       " ('유포', 46),\n",
       " ('휴스턴', 45),\n",
       " ('이광구', 45),\n",
       " ('월드', 45),\n",
       " ('카투사', 45),\n",
       " ('토토', 45),\n",
       " ('배당', 45),\n",
       " ('피파', 45),\n",
       " ('대화방', 45),\n",
       " ('월요일', 45),\n",
       " ('시리즈', 45),\n",
       " ('창원터널', 45),\n",
       " ('사다리', 45),\n",
       " ('문희옥', 45),\n",
       " ('이상', 45),\n",
       " ('기준', 45),\n",
       " ('점', 45),\n",
       " ('원', 43),\n",
       " ('로이', 42),\n",
       " ('입건', 42),\n",
       " ('본명', 40),\n",
       " ('확인', 37),\n",
       " ('카카오톡', 37),\n",
       " ('정보', 37),\n",
       " ('29', 36),\n",
       " ('법', 36),\n",
       " ('위반', 36),\n",
       " ('30', 36),\n",
       " ('통신망', 36),\n",
       " ('김정환', 34),\n",
       " ('이야기', 28),\n",
       " ('년', 27),\n",
       " ('불법', 26),\n",
       " ('연예인', 25),\n",
       " ('촬영', 25),\n",
       " ('경찰', 22),\n",
       " ('기사', 17),\n",
       " ('승리', 17),\n",
       " ('룸', 16),\n",
       " ('노래', 16),\n",
       " ('그룹', 15),\n",
       " ('범죄', 14),\n",
       " ('전범', 14),\n",
       " ('다행', 14),\n",
       " ('마르크스', 14),\n",
       " ('동일', 14),\n",
       " ('카메라', 14),\n",
       " ('서적', 14),\n",
       " ('거란', 14),\n",
       " ('친일파', 14),\n",
       " ('인물', 14),\n",
       " ('니콘', 14),\n",
       " ('전', 14),\n",
       " ('성범죄', 14),\n",
       " ('발작', 14),\n",
       " ('사실', 13),\n",
       " ('출연', 13),\n",
       " ('영상', 13),\n",
       " ('강인', 12),\n",
       " ('공유', 12),\n",
       " ('슈퍼주니어', 12),\n",
       " ('수사', 10),\n",
       " ('사건', 10),\n",
       " ('의혹', 10),\n",
       " ('혐의', 10),\n",
       " ('등장', 10),\n",
       " ('마약', 10),\n",
       " ('부실', 10),\n",
       " ('대체', 9),\n",
       " ('피해자', 9),\n",
       " ('피해자들', 9),\n",
       " ('최종훈', 9),\n",
       " ('먹이', 8),\n",
       " ('범죄자', 8),\n",
       " ('삭제', 8),\n",
       " ('여성', 8),\n",
       " ('멤버', 8),\n",
       " ('문제', 8),\n",
       " ('특정', 7),\n",
       " ('조사', 7),\n",
       " ('보기', 7),\n",
       " ('다시', 7),\n",
       " ('조선', 7),\n",
       " ('보도', 7),\n",
       " ('비호', 7),\n",
       " ('박상', 7),\n",
       " ('방송사', 7),\n",
       " ('사과', 7),\n",
       " ('정작', 7),\n",
       " ('삼', 7),\n",
       " ('수', 7),\n",
       " ('방송', 7),\n",
       " ('전광', 7),\n",
       " ('위원', 7),\n",
       " ('암시', 7),\n",
       " ('채널', 7),\n",
       " ('이종현', 6),\n",
       " ('김상우', 6),\n",
       " ('유착', 6),\n",
       " ('사회', 6),\n",
       " ('관계', 6),\n",
       " ('서울', 6),\n",
       " ('드', 6),\n",
       " ('성', 6),\n",
       " ('플러그', 6),\n",
       " ('사진', 6),\n",
       " ('그린', 6),\n",
       " ('갖가지', 5),\n",
       " ('물의', 5),\n",
       " ('동영상', 5),\n",
       " ('시적', 5),\n",
       " ('이', 5),\n",
       " ('최근', 5),\n",
       " ('09', 5),\n",
       " ('성매매', 5),\n",
       " ('씨', 5),\n",
       " ('습', 5),\n",
       " ('알선', 5),\n",
       " ('정지', 5),\n",
       " ('참여자', 4),\n",
       " ('측', 4),\n",
       " ('가해자', 4),\n",
       " ('이름', 4),\n",
       " ('실명', 4),\n",
       " ('10년', 4),\n",
       " ('명', 4),\n",
       " ('명단', 4),\n",
       " ('지목', 4),\n",
       " ('간', 4),\n",
       " ('일', 4),\n",
       " ('대화', 4),\n",
       " ('황하나', 4),\n",
       " ('정품', 4),\n",
       " ('참고인', 4),\n",
       " ('공개', 4),\n",
       " ('뉴스데스크', 4),\n",
       " ('팬', 3),\n",
       " ('현역', 3),\n",
       " ('군인', 3),\n",
       " ('거', 3),\n",
       " ('주', 3),\n",
       " ('군대', 3),\n",
       " ('파문', 3),\n",
       " ('비아그라', 3),\n",
       " ('368', 3),\n",
       " ('음악', 3),\n",
       " ('신분', 3),\n",
       " ('5000', 3),\n",
       " ('영화', 3),\n",
       " ('원매', 3),\n",
       " ('주최', 3),\n",
       " ('계정', 3),\n",
       " ('씨엔블루', 3),\n",
       " ('여파', 3),\n",
       " ('죄의식', 3),\n",
       " ('김', 3),\n",
       " ('실망감', 3),\n",
       " ('있다', 3),\n",
       " ('취소', 3),\n",
       " ('페스티벌', 3),\n",
       " ('자체', 2),\n",
       " ('환자', 2),\n",
       " ('뉴스', 2),\n",
       " ('안', 2),\n",
       " ('피의자', 2),\n",
       " ('이슈', 2),\n",
       " ('이랑', 2),\n",
       " ('공식', 2),\n",
       " ('김홍', 2),\n",
       " ('끝', 2),\n",
       " ('장자연', 2),\n",
       " ('조치', 2),\n",
       " ('강간', 2),\n",
       " ('새끼', 2),\n",
       " ('임', 2),\n",
       " ('구속', 2),\n",
       " ('게이트', 2),\n",
       " ('박영선', 2),\n",
       " ('탁주', 2),\n",
       " ('처벌', 2),\n",
       " ('모', 2),\n",
       " ('종합', 2),\n",
       " ('반성', 2),\n",
       " ('택', 2),\n",
       " ('경찰청', 1),\n",
       " ('스케일', 1),\n",
       " ('종용', 1),\n",
       " ('누', 1),\n",
       " ('참여', 1),\n",
       " ('평', 1),\n",
       " ('동네', 1),\n",
       " ('왜곡', 1),\n",
       " ('기피', 1),\n",
       " ('정리', 1),\n",
       " ('매', 1),\n",
       " ('냐', 1),\n",
       " ('운동', 1),\n",
       " ('몸종', 1),\n",
       " ('평소', 1),\n",
       " ('응원', 1),\n",
       " ('소환', 1),\n",
       " ('정', 1),\n",
       " ('리스트', 1),\n",
       " ('약물', 1),\n",
       " ('티', 1),\n",
       " ('도운', 1),\n",
       " ('물', 1),\n",
       " ('예정', 1),\n",
       " ('인멸', 1),\n",
       " ('총장', 1),\n",
       " ('언론사', 1),\n",
       " ('글자', 1),\n",
       " ('블로그', 1),\n",
       " ('지방', 1),\n",
       " ('모의', 1),\n",
       " ('연예', 1),\n",
       " ('아시아나항공', 1),\n",
       " ('교회', 1),\n",
       " ('중', 1),\n",
       " ('일상', 1),\n",
       " ('정동', 1),\n",
       " ('음행', 1),\n",
       " ('싸이', 1),\n",
       " ('사태', 1),\n",
       " ('핵폭탄', 1),\n",
       " ('신', 1),\n",
       " ('쪽', 1),\n",
       " ('동급', 1),\n",
       " ('소멸', 1),\n",
       " ('유명인', 1),\n",
       " ('송치', 1),\n",
       " ('빈', 1),\n",
       " ('이정현', 1),\n",
       " ('게', 1),\n",
       " ('진실', 1),\n",
       " ('후드', 1),\n",
       " ('근원지', 1),\n",
       " ('핸드폰', 1),\n",
       " ('여자', 1),\n",
       " ('한류', 1),\n",
       " ('프티', 1),\n",
       " ('남성', 1),\n",
       " ('니다', 1),\n",
       " ('오해', 1),\n",
       " ('쓰레기', 1),\n",
       " ('거지', 1),\n",
       " ('발언', 1),\n",
       " ('소비', 1),\n",
       " ('시선', 1),\n",
       " ('단독', 1),\n",
       " ('주황색', 1),\n",
       " ('강원도', 1),\n",
       " ('기', 1),\n",
       " ('에', 1),\n",
       " ('목사', 1),\n",
       " ('불바다', 1),\n",
       " ('스티븐', 1),\n",
       " ('박', 1),\n",
       " ('소식', 1),\n",
       " ('장관', 1),\n",
       " ('회개', 1),\n",
       " ('제기', 1),\n",
       " ('곽상도', 1),\n",
       " ('버림', 1),\n",
       " ('인가', 1),\n",
       " ('예능', 1),\n",
       " ('단체', 1),\n",
       " ('생각', 1),\n",
       " ('재난', 1),\n",
       " ('접대', 1),\n",
       " ('성적', 1),\n",
       " ('아니', 1),\n",
       " ('환장', 1),\n",
       " ('돈', 1),\n",
       " ('손자', 1),\n",
       " ('침례교회', 1),\n",
       " ('마무리', 1),\n",
       " ('가격', 1),\n",
       " ('공중분해', 1),\n",
       " ('초반', 1),\n",
       " ('해피투게더', 1),\n",
       " ('들', 1),\n",
       " ('파장', 1),\n",
       " ('때', 1),\n",
       " ('로버트 할리', 1),\n",
       " ('아이즈', 1),\n",
       " ('빙', 1),\n",
       " ('예상', 1),\n",
       " ('연', 1),\n",
       " ('윗선', 1),\n",
       " ('조율', 1),\n",
       " ('영향', 1),\n",
       " ('재벌', 1),\n",
       " ('폐지', 1),\n",
       " ('수신료', 1),\n",
       " ('제보자', 1),\n",
       " ('판매', 1),\n",
       " ('이승현', 1),\n",
       " ('뿐', 1),\n",
       " ('조명', 1),\n",
       " ('인식', 1),\n",
       " ('군가', 1),\n",
       " ('짓거리', 1),\n",
       " ('도학', 1),\n",
       " ('노래방', 1),\n",
       " ('남', 1),\n",
       " ('장수', 1),\n",
       " ('소속사', 1),\n",
       " ('기록', 1),\n",
       " ('나중', 1),\n",
       " ('얘기', 1),\n",
       " ('실세', 1),\n",
       " ('겁', 1),\n",
       " ('제출', 1),\n",
       " ('막걸리', 1),\n",
       " ('이용', 1),\n",
       " ('소비자', 1),\n",
       " ('초점', 1),\n",
       " ('도박', 1),\n",
       " ('사랑', 1),\n",
       " ('검찰', 1),\n",
       " ('당장', 1),\n",
       " ('품', 1),\n",
       " ('문화', 1),\n",
       " ('출석', 1),\n",
       " ('멸망', 1),\n",
       " ('오늘', 1),\n",
       " ('시발', 1),\n",
       " ('다', 1),\n",
       " ('내', 1),\n",
       " ('압수', 1),\n",
       " ('삼재', 1),\n",
       " ('출처', 1),\n",
       " ('베', 1),\n",
       " ('시청', 1),\n",
       " ('국가', 1),\n",
       " ('범', 1),\n",
       " ('저질', 1),\n",
       " ('국회의원', 1),\n",
       " ('일정', 1),\n",
       " ('동이', 1),\n",
       " ('니들', 1),\n",
       " ('놀이', 1),\n",
       " ('여초', 1),\n",
       " ('사시', 1),\n",
       " ('해', 1),\n",
       " ('증거', 1),\n",
       " ('분', 1),\n",
       " ('감수성', 1),\n",
       " ('변질', 1),\n",
       " ('멘트', 1),\n",
       " ('저급', 1),\n",
       " ('용기', 1),\n",
       " ('제임스', 1),\n",
       " ('추락', 1),\n",
       " ('개인', 1),\n",
       " ('참', 1),\n",
       " ('이구', 1),\n",
       " ('폭', 1),\n",
       " ('계기', 1),\n",
       " ('정신병', 1),\n",
       " ('가능', 1),\n",
       " ('자세', 1),\n",
       " ('탈세', 1),\n",
       " ('아일랜드', 1),\n",
       " ('채용', 1),\n",
       " ('과거', 1),\n",
       " ('운영', 1),\n",
       " ('팝', 1),\n",
       " ('뱀띠', 1),\n",
       " ('폰', 1),\n",
       " ('병역', 1),\n",
       " ('언스', 1),\n",
       " ('공정', 1),\n",
       " ('아들', 1),\n",
       " ('장원영', 1),\n",
       " ('킹', 1),\n",
       " ('간음', 1),\n",
       " ('장송', 1),\n",
       " ('가입', 1),\n",
       " ('말', 1),\n",
       " ('송', 1),\n",
       " ('건', 1),\n",
       " ('어벤져스', 0),\n",
       " ('코미', 0),\n",
       " ('술고래', 0),\n",
       " ('고창', 0),\n",
       " ('자동차보험', 0),\n",
       " ('카밀라', 0),\n",
       " ('연설', 0),\n",
       " ('패션쇼', 0),\n",
       " ('오빠야', 0),\n",
       " ('컨트롤러', 0),\n",
       " ('봉산동', 0),\n",
       " ('잡스', 0),\n",
       " ('호기', 0),\n",
       " ('광맥', 0),\n",
       " ('승리 투수', 0),\n",
       " ('보디빌딩', 0),\n",
       " ('가라사대', 0),\n",
       " ('화원', 0),\n",
       " ('돌진', 0),\n",
       " ('조항', 0),\n",
       " ('헬레', 0),\n",
       " ('교가', 0),\n",
       " ('뉴시스', 0),\n",
       " ('비웃음', 0),\n",
       " ('교육 문제', 0),\n",
       " ('일상물', 0),\n",
       " ('심부전증', 0),\n",
       " ('불닭볶음면', 0),\n",
       " ('2014', 0),\n",
       " ('민경욱', 0),\n",
       " ('도조 히데키', 0),\n",
       " ('도첩제', 0),\n",
       " ('신비주의', 0),\n",
       " ('부홍', 0),\n",
       " ('다과', 0),\n",
       " ('악역', 0),\n",
       " ('패치', 0),\n",
       " ('피진', 0),\n",
       " ('청자', 0),\n",
       " ('5월 8일', 0),\n",
       " ('보안', 0),\n",
       " ('토이', 0),\n",
       " ('반타작', 0),\n",
       " ('건들', 0),\n",
       " ('독산동', 0),\n",
       " ('트와이스', 0),\n",
       " ('텔레비전', 0),\n",
       " ('열광', 0),\n",
       " ('양탄자', 0),\n",
       " ('무법', 0),\n",
       " ('자바스크립트', 0),\n",
       " ('호두과자', 0),\n",
       " ('차훈', 0),\n",
       " ('격동기', 0),\n",
       " ('커피숍', 0),\n",
       " ('대원군', 0),\n",
       " ('점박이', 0),\n",
       " ('호스', 0),\n",
       " ('해상자위대', 0),\n",
       " ('목민심서', 0),\n",
       " ('비룡', 0),\n",
       " ('상서', 0),\n",
       " ('이핀', 0),\n",
       " ('코제', 0),\n",
       " ('역정', 0),\n",
       " ('소화', 0),\n",
       " ('순창', 0),\n",
       " ('멘스', 0),\n",
       " ('데모크리토스', 0),\n",
       " ('켄트', 0),\n",
       " ('마감', 0),\n",
       " ('금오공대', 0),\n",
       " ('아메리칸 파이', 0),\n",
       " ('기회주의', 0),\n",
       " ('457', 0),\n",
       " ('야만족', 0),\n",
       " ('전라북도', 0),\n",
       " ('콜라', 0),\n",
       " ('커제', 0),\n",
       " ('280', 0),\n",
       " ('보상', 0),\n",
       " ('다나와', 0),\n",
       " ('무속인', 0),\n",
       " ('플라이트', 0),\n",
       " ('대출금', 0),\n",
       " ('진찰', 0),\n",
       " ('박규원', 0),\n",
       " ('강남구청역', 0),\n",
       " ('후계', 0),\n",
       " ('조합장', 0),\n",
       " ('신은', 0),\n",
       " ('김은환', 0),\n",
       " ('순이', 0),\n",
       " ('후불', 0),\n",
       " ('예산', 0),\n",
       " ('기소독점주의', 0),\n",
       " ('음표', 0),\n",
       " ('모닝카페', 0),\n",
       " ('무미건조', 0),\n",
       " ('상반', 0),\n",
       " ('홍위병', 0),\n",
       " ('본의', 0),\n",
       " ('압둘라', 0),\n",
       " ('유인원', 0),\n",
       " ('방향성', 0),\n",
       " ('과로', 0),\n",
       " ('묵념', 0),\n",
       " ('바이퍼', 0),\n",
       " ('생동', 0),\n",
       " ('김영명', 0),\n",
       " ('정책실장', 0),\n",
       " ('그라스', 0),\n",
       " ('지방교회', 0),\n",
       " ('미찌꼬', 0),\n",
       " ('맞교환', 0),\n",
       " ('불린', 0),\n",
       " ('사부사부', 0),\n",
       " ('밴쿠버', 0),\n",
       " ('현직', 0),\n",
       " ('기획력', 0),\n",
       " ('장 주네', 0),\n",
       " ('통령', 0),\n",
       " ('변기통', 0),\n",
       " ('석대로', 0),\n",
       " ('썬더', 0),\n",
       " ('여하', 0),\n",
       " ('트릭스터', 0),\n",
       " ('울산대', 0),\n",
       " ('소과', 0),\n",
       " ('장담', 0),\n",
       " ('백지화', 0),\n",
       " ('지압', 0),\n",
       " ('신경증', 0),\n",
       " ('금배지', 0),\n",
       " ('백복령', 0),\n",
       " ('윤동기', 0),\n",
       " ('게라', 0),\n",
       " ('왜군', 0),\n",
       " ('예술단', 0),\n",
       " ('문재인', 0),\n",
       " ('공범', 0),\n",
       " ('분임', 0),\n",
       " ('마두동', 0),\n",
       " ('배철수의 음악캠프', 0),\n",
       " ('중소기업진흥공단', 0),\n",
       " ('의령군', 0),\n",
       " ('찰보리빵', 0),\n",
       " ('발라드', 0),\n",
       " ('대한노인회', 0),\n",
       " ('장전', 0),\n",
       " ('빙수', 0),\n",
       " ('레플리카', 0),\n",
       " ('남승희', 0),\n",
       " ('길 위에서', 0),\n",
       " ('현재가치', 0),\n",
       " ('포켓볼', 0),\n",
       " ('남섬', 0),\n",
       " ('누가', 0),\n",
       " ('264', 0),\n",
       " ('강서', 0),\n",
       " ('어댑터', 0),\n",
       " ('홍제', 0),\n",
       " ('의열단', 0),\n",
       " ('당나라', 0),\n",
       " ('베이비 샤워', 0),\n",
       " ('산티아고', 0),\n",
       " ('표준', 0),\n",
       " ('부처', 0),\n",
       " ('김향기', 0),\n",
       " ('논픽션', 0),\n",
       " ('작약', 0),\n",
       " ('김지유', 0),\n",
       " ('한니발', 0),\n",
       " ('라이프치히', 0),\n",
       " ('히라노', 0),\n",
       " ('할머니', 0),\n",
       " ('민영기', 0),\n",
       " ('주빈', 0),\n",
       " ('늘그막', 0),\n",
       " ('평시', 0),\n",
       " ('등수', 0),\n",
       " ('소식지', 0),\n",
       " ('로데오', 0),\n",
       " ('남조', 0),\n",
       " ('바라카', 0),\n",
       " ('마즈', 0),\n",
       " ('경쟁자', 0),\n",
       " ('씨방', 0),\n",
       " ('리알', 0),\n",
       " ('핑크', 0),\n",
       " ('충무', 0),\n",
       " ('한천', 0),\n",
       " ('일수', 0),\n",
       " ('마디', 0),\n",
       " ('윤성환', 0),\n",
       " ('손수호', 0),\n",
       " ('분리수거', 0),\n",
       " ('전가을', 0),\n",
       " ('고등학교', 0),\n",
       " ('반공', 0),\n",
       " ('후임', 0),\n",
       " ('체결', 0),\n",
       " ('중주', 0),\n",
       " ('만치', 0),\n",
       " ('일본의 아이돌', 0),\n",
       " ('메모리', 0),\n",
       " ('하얀색', 0),\n",
       " ('춘향제', 0),\n",
       " ('가열', 0),\n",
       " ('무송', 0),\n",
       " ('미드나', 0),\n",
       " ('성과급', 0),\n",
       " ('집집', 0),\n",
       " ('마이애미', 0),\n",
       " ('기총', 0),\n",
       " ('풍속계', 0),\n",
       " ('어미', 0),\n",
       " ('잡상인', 0),\n",
       " ('민이', 0),\n",
       " ('식물', 0),\n",
       " ('문회', 0),\n",
       " ('웃는 남자', 0),\n",
       " ('카바', 0),\n",
       " ('간의', 0),\n",
       " ('절제', 0),\n",
       " ('집회', 0),\n",
       " ('통감', 0),\n",
       " ('중년', 0),\n",
       " ('실연', 0),\n",
       " ('연평도', 0),\n",
       " ('7호선', 0),\n",
       " ('류수영', 0),\n",
       " ('영농', 0),\n",
       " ('고지라', 0),\n",
       " ('장준', 0),\n",
       " ('온방', 0),\n",
       " ('젠가', 0),\n",
       " ('정치부', 0),\n",
       " ('아사히', 0),\n",
       " ('진술조서', 0),\n",
       " ('상종', 0),\n",
       " ('수잔', 0),\n",
       " ('합의', 0),\n",
       " ('민우', 0),\n",
       " ('금화', 0),\n",
       " ('한술', 0),\n",
       " ('코러스', 0),\n",
       " ('구정', 0),\n",
       " ('해피해피', 0),\n",
       " ('징역', 0),\n",
       " ('페어', 0),\n",
       " ('60분', 0),\n",
       " ('치료법', 0),\n",
       " ('도야', 0),\n",
       " ('공소', 0),\n",
       " ('세러', 0),\n",
       " ('연세로', 0),\n",
       " ('패스트', 0),\n",
       " ('점이', 0),\n",
       " ('마스카라', 0),\n",
       " ('우라늄', 0),\n",
       " ('표현력', 0),\n",
       " ('미비', 0),\n",
       " ('배경', 0),\n",
       " ('탁구', 0),\n",
       " ('투혼', 0),\n",
       " ('세작', 0),\n",
       " ('지방민', 0),\n",
       " ('매몰', 0),\n",
       " ('칼', 0),\n",
       " ('대유', 0),\n",
       " ('손중', 0),\n",
       " ('다자이 오사무', 0),\n",
       " ('산간', 0),\n",
       " ('해명', 0),\n",
       " ('예인', 0),\n",
       " ('본심', 0),\n",
       " ('분식회계', 0),\n",
       " ('수심', 0),\n",
       " ('대산읍', 0),\n",
       " ('불통', 0),\n",
       " ('쿠웨이트', 0),\n",
       " ('삶의 질', 0),\n",
       " ('플라토닉', 0),\n",
       " ('드라이버', 0),\n",
       " ('갤러리', 0),\n",
       " ('중전', 0),\n",
       " ('고위', 0),\n",
       " ('천본앵', 0),\n",
       " ('코앞', 0),\n",
       " ('명성황후', 0),\n",
       " ('오진', 0),\n",
       " ('코오롱', 0),\n",
       " ('미디어텍', 0),\n",
       " ('세모', 0),\n",
       " ('복시', 0),\n",
       " ('고양이 카페', 0),\n",
       " ('초동', 0),\n",
       " ('자유인', 0),\n",
       " ('살라', 0),\n",
       " ('위기감', 0),\n",
       " ('린리', 0),\n",
       " ('야사', 0),\n",
       " ('동행인', 0),\n",
       " ('쟁탈전', 0),\n",
       " ('사미', 0),\n",
       " ('손도', 0),\n",
       " ('부엉이', 0),\n",
       " ('핀란드', 0),\n",
       " ('동림동', 0),\n",
       " ('승패', 0),\n",
       " ('218', 0),\n",
       " ('박준규', 0),\n",
       " ('이박사', 0),\n",
       " ('차이링', 0),\n",
       " ('박쥐', 0),\n",
       " ('유로파', 0),\n",
       " ('개변', 0),\n",
       " ('흑색종', 0),\n",
       " ('면식', 0),\n",
       " ('술탄', 0),\n",
       " ('법등', 0),\n",
       " ('구판', 0),\n",
       " ('소동', 0),\n",
       " ('점성', 0),\n",
       " ('명동', 0),\n",
       " ('간암', 0),\n",
       " ('경외', 0),\n",
       " ('무신', 0),\n",
       " ('가속도', 0),\n",
       " ('작법', 0),\n",
       " ('범피', 0),\n",
       " ('유효', 0),\n",
       " ('오대산', 0),\n",
       " ('경유지', 0),\n",
       " ('트레이드', 0),\n",
       " ('환국', 0),\n",
       " ('사인회', 0),\n",
       " ('촉수', 0),\n",
       " ('근성', 0),\n",
       " ('트레', 0),\n",
       " ('전시', 0),\n",
       " ('조양호', 0),\n",
       " ('모국어', 0),\n",
       " ('중장', 0),\n",
       " ('성산구', 0),\n",
       " ('발뺌', 0),\n",
       " ('옴니버스', 0),\n",
       " ('스트라빈스키', 0),\n",
       " ('옷걸이', 0),\n",
       " ('우작', 0),\n",
       " ('태즈먼', 0),\n",
       " ('산등성이', 0),\n",
       " ('조지 버나드 쇼', 0),\n",
       " ('보소', 0),\n",
       " ('진태', 0),\n",
       " ('용산역', 0),\n",
       " ('현대사', 0),\n",
       " ('4월 27일', 0),\n",
       " ('우범', 0),\n",
       " ('수도자', 0),\n",
       " ('살생', 0),\n",
       " ('문혜원', 0),\n",
       " ('우물가', 0),\n",
       " ('강요죄', 0),\n",
       " ('신혜식', 0),\n",
       " ('준호', 0),\n",
       " ('스승', 0),\n",
       " ('찬', 0),\n",
       " ('연상', 0),\n",
       " ('시신경', 0),\n",
       " ('서준식', 0),\n",
       " ('난민', 0),\n",
       " ('질도', 0),\n",
       " ('공백', 0),\n",
       " ('트리트먼트', 0),\n",
       " ('가치', 0),\n",
       " ('간첩 작전', 0),\n",
       " ('로사', 0),\n",
       " ('청소', 0),\n",
       " ('흑기사', 0),\n",
       " ('작업복', 0),\n",
       " ('도요', 0),\n",
       " ('문방구', 0),\n",
       " ('삼지연', 0),\n",
       " ('페어플레이', 0),\n",
       " ('정유미', 0),\n",
       " ('노미', 0),\n",
       " ('모욕감', 0),\n",
       " ('시대정신', 0),\n",
       " ('그림일기', 0),\n",
       " ('구름', 0),\n",
       " ('유통기한', 0),\n",
       " ('피카르', 0),\n",
       " ('뱅크', 0),\n",
       " ('첫경험', 0),\n",
       " ('승무원', 0),\n",
       " ('출전', 0),\n",
       " ('립', 0),\n",
       " ('성나라', 0),\n",
       " ('향락', 0),\n",
       " ('방정오', 0),\n",
       " ('옥테인', 0),\n",
       " ('싯다르타', 0),\n",
       " ('시집', 0),\n",
       " ('이프', 0),\n",
       " ('불갑산', 0),\n",
       " ('회사원', 0),\n",
       " ('데저트 이글', 0),\n",
       " ('정원', 0),\n",
       " ('박세리', 0),\n",
       " ('183', 0),\n",
       " ('의문점', 0),\n",
       " ('523', 0),\n",
       " ('썰물', 0),\n",
       " ('팀원', 0),\n",
       " ('구화', 0),\n",
       " ('이상일', 0),\n",
       " ('난조', 0),\n",
       " ('사당', 0),\n",
       " ('폭발물', 0),\n",
       " ('파일 크기', 0),\n",
       " ('윙와', 0),\n",
       " ('장세동', 0),\n",
       " ('계급장', 0),\n",
       " ('이선호', 0),\n",
       " ('극대', 0),\n",
       " ('투우', 0),\n",
       " ('23', 0),\n",
       " ('로', 0),\n",
       " ('풍백', 0),\n",
       " ('미오', 0),\n",
       " ('관사', 0),\n",
       " ('고흥군', 0),\n",
       " ('친권자', 0),\n",
       " ('정예인', 0),\n",
       " ('작사', 0),\n",
       " ('다산', 0),\n",
       " ('한국산업기술대학교', 0),\n",
       " ('스플래툰', 0),\n",
       " ('아크릴', 0),\n",
       " ('예정일', 0),\n",
       " ('자멸', 0),\n",
       " ('마리나', 0),\n",
       " ('조목조목', 0),\n",
       " ('배사', 0),\n",
       " ('나으리', 0),\n",
       " ('꽃비', 0),\n",
       " ('산세', 0),\n",
       " ('몰수', 0),\n",
       " ('이건욱', 0),\n",
       " ('주제곡', 0),\n",
       " ('망자', 0),\n",
       " ('해설자', 0),\n",
       " ('로그', 0),\n",
       " ('등급', 0),\n",
       " ('폭죽', 0),\n",
       " ('반의어', 0),\n",
       " ('한보람', 0),\n",
       " ('동명사', 0),\n",
       " ('홈구장', 0),\n",
       " ('환호', 0),\n",
       " ('관람석', 0),\n",
       " ('성태', 0),\n",
       " ('선어', 0),\n",
       " ('사랑비', 0),\n",
       " ('요직', 0),\n",
       " ('반신반의', 0),\n",
       " ('임명', 0),\n",
       " ('컴백', 0),\n",
       " ('고교', 0),\n",
       " ('어거지', 0),\n",
       " ('내용', 0),\n",
       " ('311', 0),\n",
       " ('김용태', 0),\n",
       " ('슈게이징', 0),\n",
       " ('비례', 0),\n",
       " ('원룸', 0),\n",
       " ('건설사', 0),\n",
       " ('2월', 0),\n",
       " ('기수', 0),\n",
       " ('주사파', 0),\n",
       " ('잡새', 0),\n",
       " ('올빼미', 0),\n",
       " ('기호학', 0),\n",
       " ('던지기', 0),\n",
       " ('언놈', 0),\n",
       " ('단역', 0),\n",
       " ('복장', 0),\n",
       " ('무더기', 0),\n",
       " ('이어폰', 0),\n",
       " ('이익선', 0),\n",
       " ('가해', 0),\n",
       " ('아신', 0),\n",
       " ('심규혁', 0),\n",
       " ('국왕', 0),\n",
       " ('조나단 파', 0),\n",
       " ('쇼스타코비치', 0),\n",
       " ('철칙', 0),\n",
       " ('기행', 0),\n",
       " ('초록색', 0),\n",
       " ('특별법', 0),\n",
       " ('경제부', 0),\n",
       " ('미추홀', 0),\n",
       " ('속도계', 0),\n",
       " ('필요시', 0),\n",
       " ('순천향대', 0),\n",
       " ('김무관', 0),\n",
       " ('풀라', 0),\n",
       " ('해원', 0),\n",
       " ('불공', 0),\n",
       " ('공통점', 0),\n",
       " ('조복', 0),\n",
       " ('리니지', 0),\n",
       " ('청장', 0),\n",
       " ('주간', 0),\n",
       " ('발굴', 0),\n",
       " ('해총', 0),\n",
       " ('물질', 0),\n",
       " ('쓸데', 0),\n",
       " ('땅속', 0),\n",
       " ('선정릉', 0),\n",
       " ('미도', 0),\n",
       " ('반찬', 0),\n",
       " ('총검', 0),\n",
       " ('이벽', 0),\n",
       " ('번민', 0),\n",
       " ('조합원', 0),\n",
       " ('좀약', 0),\n",
       " ('이대점', 0),\n",
       " ('건투', 0),\n",
       " ('머니투데이', 0),\n",
       " ('향당', 0),\n",
       " ('과실', 0),\n",
       " ('파일럿 프로그램', 0),\n",
       " ('저혈압', 0),\n",
       " ('방송물', 0),\n",
       " ('대명', 0),\n",
       " ('흑자', 0),\n",
       " ('반 다이크', 0),\n",
       " ('장막', 0),\n",
       " ('전당포', 0),\n",
       " ('포토', 0),\n",
       " ('샤니', 0),\n",
       " ('성기사', 0),\n",
       " ('240', 0),\n",
       " ('이지연', 0),\n",
       " ('까치', 0),\n",
       " ('오산', 0),\n",
       " ('제임스 건', 0),\n",
       " ('전승', 0),\n",
       " ('중부내륙선', 0),\n",
       " ('실행의 착수', 0),\n",
       " ('진리교', 0),\n",
       " ('임동진', 0),\n",
       " ('전형', 0),\n",
       " ('종이접기', 0),\n",
       " ('알고 싶어요', 0),\n",
       " ('디스켓', 0),\n",
       " ('원탁', 0),\n",
       " ('에게 해', 0),\n",
       " ('식전', 0),\n",
       " ('주재', 0),\n",
       " ('교대자', 0),\n",
       " ('운당', 0),\n",
       " ('통쾌', 0),\n",
       " ('중앙은행', 0),\n",
       " ('등지', 0),\n",
       " ('한마음병원', 0),\n",
       " ('썰', 0),\n",
       " ('포기', 0),\n",
       " ('웰시', 0),\n",
       " ('태현', 0),\n",
       " ('신고합니다', 0),\n",
       " ('고어', 0),\n",
       " ('중범죄', 0),\n",
       " ('이계성', 0),\n",
       " ('글리', 0),\n",
       " ('강현주', 0),\n",
       " ('신작', 0),\n",
       " ('플루오린', 0),\n",
       " ('원영', 0),\n",
       " ('부산대', 0),\n",
       " ('차출', 0),\n",
       " ('김수환', 0),\n",
       " ('김영선', 0),\n",
       " ('참전', 0),\n",
       " ('천변', 0),\n",
       " ('요통', 0),\n",
       " ('2016년 8월', 0),\n",
       " ('포로', 0),\n",
       " ('대진표', 0),\n",
       " ('아파트', 0),\n",
       " ('모란', 0),\n",
       " ('불사조', 0),\n",
       " ('관능', 0),\n",
       " ('월희', 0),\n",
       " ('뒤편', 0),\n",
       " ('작장면', 0),\n",
       " ('하늘', 0),\n",
       " ('시술', 0),\n",
       " ('서바이벌', 0),\n",
       " ('봉신', 0),\n",
       " ('큰비', 0),\n",
       " ('뉴에이지', 0),\n",
       " ('하재', 0),\n",
       " ...]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related keywords from news artivle , sns. comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
